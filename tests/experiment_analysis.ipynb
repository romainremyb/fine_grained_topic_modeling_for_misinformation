{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "import re, nltk\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn, gensim\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n",
    "from gensim.corpora import Dictionary\n",
    "from collections import defaultdict\n",
    "import statsmodels.api as sm\n",
    "sys.path.append(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/src/')\n",
    "sys.path.append(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/src/')\n",
    "os.chdir(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/data/')\n",
    "from utils import preprocess_for_bow, experiment_result\n",
    "from models.lda import LDAwrappers\n",
    "from models.hdp import HDPwrapper\n",
    "from models.gsdmm import MovieGroupProcessWrapper\n",
    "from models.lftm import LFTMwrapper\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"google/flan-t5-base\"\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Science/Tech\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Generate responses\n",
    "output = model.generate(input_ids, max_length=100, num_return_sequences=1, num_beams=4)\n",
    "\n",
    "# Decode and print the generated text\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_topic_titles(experiment_result, exp_number):\n",
    "    exp_id=\"exp_{}\".format(exp_number)\n",
    "    n=1\n",
    "    for keywords in experiment_result[exp_id]['word_topic_pvalues']:\n",
    "        prompt = \"I have a topic described by the following keywords: [{}]. Based on the previous keywords, \\\n",
    "                what is this topic about?\".format(\", \".join(keywords['words']))\n",
    "        input_ids = tokenizer.encode(prompt, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "        output = model.generate(input_ids, max_length=100, num_return_sequences=1, num_beams=4)\n",
    "        generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "        print('topic',n,'generated topic name: ', generated_text)\n",
    "        n+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 1 generated topic name:  Science/Tech\n",
      "topic 2 generated topic name:  Science/Tech\n",
      "topic 3 generated topic name:  presidential candidate donald trump gets into a video of a coronavirus show hosted by president donald biden\n",
      "topic 4 generated topic name:  World\n",
      "topic 5 generated topic name:  presidential election\n",
      "topic 6 generated topic name:  Science/Tech\n",
      "topic 7 generated topic name:  World\n"
     ]
    }
   ],
   "source": [
    "gen_topic_titles(res['lda_experiment'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments_dataset1.json', 'r') as fout:\n",
    "    res=json.load(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['lda_experiment', 'gsdmm_experiment', 'hdp_experiment', 'lftm_experiment'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('experiments_dataset2.json', 'r') as fout:\n",
    "    res2=json.load(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def to_df(res):\n",
    "    params=defaultdict(list)\n",
    "    for exp in res.keys():\n",
    "        params['c_we'].append(res[exp]['coherence_metrics']['c_we']['c_we'])\n",
    "        params['c_we_std'].append(res[exp]['coherence_metrics']['c_we']['c_we_std'])\n",
    "        #params['num_topics'].append(res[exp]['number_topics'])\n",
    "        for p in res[exp]['hyperparameters'].keys():\n",
    "            params[p].append(res[exp]['hyperparameters'][p])\n",
    "    #if params['num_topics'][0]==None:\n",
    "    #    del params['num_topics']\n",
    "    return pd.DataFrame(params)\n",
    "    #return params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df2(res):\n",
    "    params=defaultdict(list)\n",
    "    for exp in res.keys():\n",
    "        params['u_mass'].append(res[exp]['coherence_metrics']['u_mass']['u_mass'])\n",
    "        params['u_mass_std'].append(res[exp]['coherence_metrics']['u_mass']['u_mass_std'])\n",
    "        #params['num_topics'].append(res[exp]['number_topics'])\n",
    "        for p in res[exp]['hyperparameters'].keys():\n",
    "            params[p].append(res[exp]['hyperparameters'][p])\n",
    "    #if params['num_topics'][0]==None:\n",
    "    #    del params['num_topics']\n",
    "    return pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_df3(res):\n",
    "    params=defaultdict(list)\n",
    "    for exp in res.keys():\n",
    "        params['excl_we'].append(res[exp]['coherence_metrics']['c_we']['excl_we'])\n",
    "        params['excl_we_std'].append(res[exp]['coherence_metrics']['c_we']['excl_we_std'])\n",
    "        #params['num_topics'].append(res[exp]['number_topics'])\n",
    "        for p in res[exp]['hyperparameters'].keys():\n",
    "            params[p].append(res[exp]['hyperparameters'][p])\n",
    "    #if params['num_topics'][0]==None:\n",
    "    #    del params['num_topics']\n",
    "    return pd.DataFrame(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## word embedding coherence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATASET 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_we</th>\n",
       "      <th>c_we_std</th>\n",
       "      <th>kappa</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.153307</td>\n",
       "      <td>0.100293</td>\n",
       "      <td>1.027593</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>1.083157</td>\n",
       "      <td>1.016308</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.140640</td>\n",
       "      <td>0.103504</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>102</td>\n",
       "      <td>0.949774</td>\n",
       "      <td>1.061169</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.139483</td>\n",
       "      <td>0.112894</td>\n",
       "      <td>1.056236</td>\n",
       "      <td>11</td>\n",
       "      <td>124</td>\n",
       "      <td>0.979222</td>\n",
       "      <td>1.123539</td>\n",
       "      <td>0.015063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.138054</td>\n",
       "      <td>0.108530</td>\n",
       "      <td>1.102683</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>1.029898</td>\n",
       "      <td>1.024214</td>\n",
       "      <td>0.037757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.135611</td>\n",
       "      <td>0.115917</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>131</td>\n",
       "      <td>0.923611</td>\n",
       "      <td>0.968796</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_we  c_we_std     kappa   K    T     alpha     gamma       eta\n",
       "23  0.153307  0.100293  1.027593  19  100  1.083157  1.016308  0.021277\n",
       "11  0.140640  0.103504  1.000000  17  102  0.949774  1.061169  0.010000\n",
       "0   0.139483  0.112894  1.056236  11  124  0.979222  1.123539  0.015063\n",
       "12  0.138054  0.108530  1.102683  14  108  1.029898  1.024214  0.037757\n",
       "10  0.135611  0.115917  1.000000  10  131  0.923611  0.968796  0.010000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda=to_df(res2['hdp_experiment'])\n",
    "lda.iloc[lda.nlargest(5, 'c_we').index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.txt', 'w') as fout:\n",
    "    for i in range(10):\n",
    "        fout.write('\\n')\n",
    "        for t in res['hdp_experiment']['exp_23']['word_topic_pvalues']:\n",
    "            fout.write(t['words'][i]+' & ')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['hdp_experiment']['exp_10']['word_topic_pvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                   c_we   R-squared:                       0.701\n",
      "Model:                            OLS   Adj. R-squared:                  0.637\n",
      "Method:                 Least Squares   F-statistic:                     10.94\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           2.86e-06\n",
      "Time:                        16:06:36   Log-Likelihood:                 128.74\n",
      "No. Observations:                  35   AIC:                            -243.5\n",
      "Df Residuals:                      28   BIC:                            -232.6\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.2011      0.039      5.151      0.000       0.121       0.281\n",
      "kappa          0.0183      0.028      0.651      0.521      -0.039       0.076\n",
      "K              0.0002      0.000      0.628      0.535      -0.000       0.001\n",
      "T             -0.0003   4.35e-05     -7.178      0.000      -0.000      -0.000\n",
      "alpha          0.0068      0.023      0.301      0.766      -0.040       0.053\n",
      "gamma         -0.0515      0.033     -1.568      0.128      -0.119       0.016\n",
      "eta           -0.3035      0.105     -2.881      0.008      -0.519      -0.088\n",
      "==============================================================================\n",
      "Omnibus:                        1.219   Durbin-Watson:                   1.883\n",
      "Prob(Omnibus):                  0.544   Jarque-Bera (JB):                0.447\n",
      "Skew:                          -0.218   Prob(JB):                        0.800\n",
      "Kurtosis:                       3.341   Cond. No.                     1.38e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.38e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "y = lda['c_we']\n",
    "x=lda.drop(columns=['c_we', 'c_we_std'])\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UMASS coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>u_mass</th>\n",
       "      <th>u_mass_std</th>\n",
       "      <th>kappa</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-5.075834</td>\n",
       "      <td>6.129790</td>\n",
       "      <td>1.027593</td>\n",
       "      <td>19</td>\n",
       "      <td>100</td>\n",
       "      <td>1.083157</td>\n",
       "      <td>1.016308</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-5.592157</td>\n",
       "      <td>6.774998</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17</td>\n",
       "      <td>102</td>\n",
       "      <td>0.949774</td>\n",
       "      <td>1.061169</td>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-5.655096</td>\n",
       "      <td>6.755908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18</td>\n",
       "      <td>115</td>\n",
       "      <td>0.919477</td>\n",
       "      <td>1.041153</td>\n",
       "      <td>0.029618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.813483</td>\n",
       "      <td>6.870791</td>\n",
       "      <td>1.102683</td>\n",
       "      <td>14</td>\n",
       "      <td>108</td>\n",
       "      <td>1.029898</td>\n",
       "      <td>1.024214</td>\n",
       "      <td>0.037757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.984140</td>\n",
       "      <td>6.929608</td>\n",
       "      <td>1.013312</td>\n",
       "      <td>10</td>\n",
       "      <td>127</td>\n",
       "      <td>0.977072</td>\n",
       "      <td>1.036959</td>\n",
       "      <td>0.029136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      u_mass  u_mass_std     kappa   K    T     alpha     gamma       eta\n",
       "23 -5.075834    6.129790  1.027593  19  100  1.083157  1.016308  0.021277\n",
       "11 -5.592157    6.774998  1.000000  17  102  0.949774  1.061169  0.010000\n",
       "26 -5.655096    6.755908  1.000000  18  115  0.919477  1.041153  0.029618\n",
       "12 -5.813483    6.870791  1.102683  14  108  1.029898  1.024214  0.037757\n",
       "9  -5.984140    6.929608  1.013312  10  127  0.977072  1.036959  0.029136"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda=to_df2(res2['hdp_experiment'])\n",
    "lda.iloc[lda.nlargest(5, 'u_mass').index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['hdp_experiment']['exp_9']['word_topic_pvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.txt', 'w') as fout:\n",
    "    for i in range(10):\n",
    "        fout.write('\\n')\n",
    "        for t in res2['hdp_experiment']['exp_15']['word_topic_pvalues']:\n",
    "            fout.write(t['words'][i]+' & ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                 u_mass   R-squared:                       0.838\n",
      "Model:                            OLS   Adj. R-squared:                  0.803\n",
      "Method:                 Least Squares   F-statistic:                     24.14\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           7.43e-10\n",
      "Time:                        16:19:48   Log-Likelihood:                -16.632\n",
      "No. Observations:                  35   AIC:                             47.26\n",
      "Df Residuals:                      28   BIC:                             58.15\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          1.1678      2.485      0.470      0.642      -3.923       6.259\n",
      "kappa          1.6949      1.795      0.944      0.353      -1.981       5.371\n",
      "K              0.0284      0.016      1.788      0.085      -0.004       0.061\n",
      "T             -0.0310      0.003    -11.186      0.000      -0.037      -0.025\n",
      "alpha         -0.1092      1.445     -0.076      0.940      -3.068       2.850\n",
      "gamma         -5.2067      2.090     -2.492      0.019      -9.487      -0.926\n",
      "eta          -18.2112      6.707     -2.715      0.011     -31.949      -4.473\n",
      "==============================================================================\n",
      "Omnibus:                        0.686   Durbin-Watson:                   1.687\n",
      "Prob(Omnibus):                  0.710   Jarque-Bera (JB):                0.119\n",
      "Skew:                          -0.082   Prob(JB):                        0.942\n",
      "Kurtosis:                       3.234   Cond. No.                     1.38e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.38e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = lda['u_mass']\n",
    "x=lda.drop(columns=['u_mass', 'u_mass_std'])\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:             u_mass_std   R-squared:                       0.905\n",
      "Model:                            OLS   Adj. R-squared:                  0.885\n",
      "Method:                 Least Squares   F-statistic:                     44.50\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           4.80e-13\n",
      "Time:                        11:29:26   Log-Likelihood:                -32.460\n",
      "No. Observations:                  35   AIC:                             78.92\n",
      "Df Residuals:                      28   BIC:                             89.81\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -7.7476      4.114     -1.883      0.070     -16.175       0.680\n",
      "kappa         14.0652      2.726      5.160      0.000       8.482      19.648\n",
      "K             -0.2444      0.020    -12.207      0.000      -0.285      -0.203\n",
      "T              0.0057      0.004      1.449      0.158      -0.002       0.014\n",
      "alpha         -0.8921      2.397     -0.372      0.713      -5.803       4.018\n",
      "gamma          1.1772      2.220      0.530      0.600      -3.370       5.725\n",
      "eta          -13.4279      9.460     -1.419      0.167     -32.805       5.950\n",
      "==============================================================================\n",
      "Omnibus:                       14.669   Durbin-Watson:                   2.469\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.362\n",
      "Skew:                          -1.158   Prob(JB):                     0.000103\n",
      "Kurtosis:                       5.688   Cond. No.                     1.28e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.28e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = lda['u_mass_std']\n",
    "x=lda.drop(columns=['u_mass', 'u_mass_std'])\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA exclusivity metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>excl_we</th>\n",
       "      <th>excl_we_std</th>\n",
       "      <th>kappa</th>\n",
       "      <th>K</th>\n",
       "      <th>T</th>\n",
       "      <th>alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>eta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.042677</td>\n",
       "      <td>0.074323</td>\n",
       "      <td>1.045834</td>\n",
       "      <td>19</td>\n",
       "      <td>194</td>\n",
       "      <td>1.027089</td>\n",
       "      <td>1.011850</td>\n",
       "      <td>0.026586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.043316</td>\n",
       "      <td>0.071076</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19</td>\n",
       "      <td>174</td>\n",
       "      <td>1.003145</td>\n",
       "      <td>1.022710</td>\n",
       "      <td>0.032313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.043470</td>\n",
       "      <td>0.081202</td>\n",
       "      <td>1.175820</td>\n",
       "      <td>14</td>\n",
       "      <td>197</td>\n",
       "      <td>1.014443</td>\n",
       "      <td>1.010659</td>\n",
       "      <td>0.036613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.048216</td>\n",
       "      <td>0.071250</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>188</td>\n",
       "      <td>1.030361</td>\n",
       "      <td>0.930585</td>\n",
       "      <td>0.016631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.050275</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10</td>\n",
       "      <td>173</td>\n",
       "      <td>0.958978</td>\n",
       "      <td>0.993384</td>\n",
       "      <td>0.038259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     excl_we  excl_we_std     kappa   K    T     alpha     gamma       eta\n",
       "13  0.042677     0.074323  1.045834  19  194  1.027089  1.011850  0.026586\n",
       "16  0.043316     0.071076  1.000000  19  174  1.003145  1.022710  0.032313\n",
       "7   0.043470     0.081202  1.175820  14  197  1.014443  1.010659  0.036613\n",
       "25  0.048216     0.071250  1.000000  10  188  1.030361  0.930585  0.016631\n",
       "21  0.050275     0.073361  1.000000  10  173  0.958978  0.993384  0.038259"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda=to_df3(res2['hdp_experiment'])\n",
    "lda.iloc[lda.nsmallest(5, 'excl_we').index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res['hdp_experiment']['exp_21']['word_topic_pvalues'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res.txt', 'w') as fout:\n",
    "    for i in range(10):\n",
    "        fout.write('\\n')\n",
    "        for t in res2['hdp_experiment']['exp_11']['word_topic_pvalues']:\n",
    "            fout.write(t['words'][i]+' & ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                excl_we   R-squared:                       0.750\n",
      "Model:                            OLS   Adj. R-squared:                  0.697\n",
      "Method:                 Least Squares   F-statistic:                     14.03\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):           2.57e-07\n",
      "Time:                        16:26:05   Log-Likelihood:                 134.11\n",
      "No. Observations:                  35   AIC:                            -254.2\n",
      "Df Residuals:                      28   BIC:                            -243.3\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1596      0.033      4.767      0.000       0.091       0.228\n",
      "kappa          0.0358      0.024      1.480      0.150      -0.014       0.085\n",
      "K              0.0003      0.000      1.589      0.123   -9.82e-05       0.001\n",
      "T             -0.0003   3.73e-05     -8.599      0.000      -0.000      -0.000\n",
      "alpha         -0.0019      0.019     -0.100      0.921      -0.042       0.038\n",
      "gamma         -0.0849      0.028     -3.014      0.005      -0.143      -0.027\n",
      "eta           -0.2302      0.090     -2.547      0.017      -0.415      -0.045\n",
      "==============================================================================\n",
      "Omnibus:                        2.168   Durbin-Watson:                   2.437\n",
      "Prob(Omnibus):                  0.338   Jarque-Bera (JB):                1.621\n",
      "Skew:                           0.339   Prob(JB):                        0.445\n",
      "Kurtosis:                       2.193   Cond. No.                     1.38e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.38e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "y = lda['excl_we']\n",
    "x=lda.drop(columns=['excl_we', 'excl_we_std'])\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y, x).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomodapiArm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
