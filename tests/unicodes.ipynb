{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re\n",
    "sys.path.append(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/src/')\n",
    "os.chdir(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/data/')\n",
    "\n",
    "import re, nltk\n",
    "from nltk import pos_tag\n",
    "\n",
    "from utils import input_to_list_string, preprocess, _init\n",
    "from tomodapi.abstract_model import AbstractModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text, idxs = input_to_list_string('data.csv', False, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'covid19 is not covid- nor covid '"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'\\b\\d+\\b'\n",
    "\n",
    "filtered_text = re.sub(pattern, '', 'covid19 is not covid-19 nor covid 19')\n",
    "filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'\\\\U[0-9A-Za-z]{8}'\n",
    "unique_Us = []\n",
    "for t in text:\n",
    "    filtered_text = re.findall(pattern, t.encode('unicode-escape').decode())\n",
    "    for u in filtered_text:\n",
    "        if u not in unique_Us:\n",
    "            unique_Us.append(u)\n",
    "\n",
    "len(unique_Us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicode ğŸ¤· as count 184\n",
      "unicode ğŸ”² as count 145\n",
      "unicode ğŸ˜„ as count 135\n",
      "unicode ğŸ¤ª as count 131\n",
      "unicode ğŸ‡± as count 104\n",
      "unicode ğŸ¤¢ as count 57\n",
      "unicode ğŸ‡¸ as count 49\n",
      "unicode ğŸ˜³ as count 44\n",
      "unicode ğŸ¤£ as count 43\n",
      "unicode ğŸ‡· as count 37\n",
      "unicode ğŸ‘¶ as count 36\n",
      "unicode ğŸ¤¬ as count 27\n",
      "unicode ğŸ‡º as count 24\n",
      "unicode ğŸ˜ as count 18\n",
      "unicode ğŸ’€ as count 18\n",
      "unicode ğŸ˜ as count 18\n",
      "unicode ğŸ˜­ as count 18\n",
      "unicode ğŸ§ as count 17\n",
      "unicode ğŸ–• as count 17\n",
      "unicode ğŸ™„ as count 15\n",
      "unicode ğŸ¥ as count 15\n",
      "unicode ğŸ¤— as count 15\n",
      "unicode ğŸ¤¦ as count 14\n",
      "unicode ğŸ˜‚ as count 13\n",
      "unicode ğŸ˜‚ as count 13\n",
      "unicode ğŸš¨ as count 13\n",
      "unicode ğŸ™„ as count 13\n",
      "unicode ğŸ¼ as count 13\n",
      "unicode ğŸ´ as count 12\n",
      "unicode ğŸ˜‚ as count 11\n",
      "unicode ğŸ’¡ as count 10\n",
      "unicode ğŸ¤” as count 10\n",
      "unicode ğŸ¤£ as count 9\n",
      "unicode ğŸ˜ as count 9\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\\\U[0-9A-Za-z]{8}'\n",
    "Us = []\n",
    "import numpy as np\n",
    "for t in text:\n",
    "    filtered_text = re.findall(pattern, t.encode('unicode-escape').decode())\n",
    "    for u in filtered_text:\n",
    "        Us.append(u)\n",
    "\n",
    "Us = np.array(Us)\n",
    "for i in range(1,35):\n",
    "    idx=np.argsort(np.unique(Us, return_counts=True)[1])[-i]\n",
    "    print(f\"unicode {Us[idx].encode('utf-8').decode('unicode-escape')} as count {np.unique(Us, return_counts=True)[1][idx]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4 character patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "487"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = r'\\\\u[0-9A-Za-z]{4}'\n",
    "unique_small_Us = []\n",
    "for t in text:\n",
    "    filtered_text = re.findall(pattern, t.encode('unicode-escape').decode())\n",
    "    for u in filtered_text:\n",
    "        if u not in unique_small_Us:\n",
    "            unique_small_Us.append(u)\n",
    "\n",
    "len(unique_small_Us)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€™\n",
      "â€¦\n",
      "â€”\n",
      "â€˜\n",
      "â€œ\n",
      "â€\n",
      "ãƒ¼\n",
      "â¬‡\n",
      "ï¸\n",
      "â€“\n",
      "âš \n",
      "âœ…\n",
      "â¤\n",
      "â„¢\n",
      "â€\n",
      "â™‚\n",
      "â˜¹\n",
      "â€¼\n",
      "âœ”\n",
      "âœ¨\n"
     ]
    }
   ],
   "source": [
    "for u in unique_small_Us[:20]:\n",
    "    print(u.encode('utf-8').decode('unicode-escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicode â€™ as count 5414\n",
      "unicode â€œ as count 2150\n",
      "unicode â€ as count 2121\n",
      "unicode â€¢ as count 1666\n",
      "unicode â€” as count 1609\n",
      "unicode â€˜ as count 368\n",
      "unicode â€¦ as count 242\n",
      "unicode ï¸ as count 232\n",
      "unicode â€“ as count 221\n",
      "unicode â€ as count 50\n",
      "unicode à¤¾ as count 45\n",
      "unicode à¤• as count 37\n",
      "unicode âœ… as count 33\n",
      "unicode âŒ as count 31\n",
      "unicode â¬‡ as count 30\n",
      "unicode â¤ as count 30\n",
      "unicode à¥ as count 28\n",
      "unicode Ä± as count 27\n",
      "unicode à¥‡ as count 26\n",
      "unicode à¤¸ as count 26\n",
      "unicode Ø§ as count 26\n",
      "unicode à¤¿ as count 24\n",
      "unicode â¦ as count 22\n",
      "unicode â© as count 22\n",
      "unicode â™€ as count 22\n",
      "unicode ã€‚ as count 21\n",
      "unicode Ä° as count 21\n",
      "unicode Ø± as count 20\n",
      "unicode â€¼ as count 20\n",
      "unicode à¤¨ as count 19\n",
      "unicode â™‚ as count 19\n",
      "unicode à¤° as count 19\n",
      "unicode à¤¹ as count 18\n",
      "unicode â­ as count 18\n",
      "unicode à¤¯ as count 18\n",
      "unicode à¥‹ as count 18\n",
      "unicode à¥€ as count 18\n",
      "unicode à¤² as count 17\n",
      "unicode ã„ as count 17\n",
      "unicode à¤® as count 16\n",
      "unicode ã® as count 16\n",
      "unicode ãƒ¼ as count 16\n",
      "unicode à¤œ as count 15\n",
      "unicode ã§ as count 15\n"
     ]
    }
   ],
   "source": [
    "pattern = r'\\\\u[0-9A-Za-z]{4}'\n",
    "small_Us = []\n",
    "import numpy as np\n",
    "for t in text:\n",
    "    filtered_text = re.findall(pattern, t.encode('unicode-escape').decode())\n",
    "    for u in filtered_text:\n",
    "        small_Us.append(u)\n",
    "\n",
    "# most popular small unicodes\n",
    "small_Us = np.array(small_Us)\n",
    "for i in range(1,45):\n",
    "    idx=np.argsort(np.unique(small_Us, return_counts=True)[1])[-i]\n",
    "    print(f\"unicode {np.unique(small_Us, return_counts=True)[0][idx].encode('utf-8').decode('unicode-escape')} as count {np.unique(small_Us, return_counts=True)[1][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unicode â¤µ as count 1\n",
      "unicode å– as count 1\n",
      "unicode å as count 1\n",
      "unicode åŠ as count 1\n",
      "unicode åŒº as count 1\n",
      "unicode åŒ– as count 1\n",
      "unicode â€• as count 1\n",
      "unicode å‹¿ as count 1\n",
      "unicode å‰µ as count 1\n",
      "unicode åˆ» as count 1\n",
      "unicode åˆ as count 1\n",
      "unicode åˆ† as count 1\n",
      "unicode å†™ as count 1\n",
      "unicode å†… as count 1\n",
      "unicode â€³ as count 1\n",
      "unicode å…¬ as count 1\n",
      "unicode â‰ as count 1\n",
      "unicode å…š as count 1\n",
      "unicode â£ as count 1\n",
      "unicode å½ as count 1\n"
     ]
    }
   ],
   "source": [
    "# print less popular unicodes\n",
    "for i in range(20):\n",
    "    idx=np.argsort(np.unique(small_Us, return_counts=True)[1])[i]\n",
    "    print(f\"unicode {np.unique(small_Us, return_counts=True)[0][idx].encode('utf-8').decode('unicode-escape')} as count {np.unique(small_Us, return_counts=True)[1][idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\\\u2015',\n",
       " '\\\\u2033',\n",
       " '\\\\u2063',\n",
       " '\\\\u0627',\n",
       " '\\\\u2066',\n",
       " '\\\\u2069',\n",
       " '\\\\u200d',\n",
       " '\\\\u2013',\n",
       " '\\\\ufe0f',\n",
       " '\\\\u2026',\n",
       " '\\\\u2018',\n",
       " '\\\\u2014',\n",
       " '\\\\u2022',\n",
       " '\\\\u201d',\n",
       " '\\\\u201c',\n",
       " '\\\\u2019']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_from_sorted_counts = [6, 14, 18, -21, -23, -24]\n",
    "l = range(-10,0)\n",
    "remove_from_sorted_counts.extend(l)\n",
    "\n",
    "unicodes_to_remove = []\n",
    "for i in remove_from_sorted_counts:\n",
    "    idx=np.argsort(np.unique(small_Us, return_counts=True)[1])[i]\n",
    "    unicodes_to_remove.append(np.unique(small_Us, return_counts=True)[0][idx])\n",
    "\n",
    "unicodes_to_remove\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "unicodes to remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â€•\n",
      "â€³\n",
      "â£\n",
      "Ø§\n",
      "â¦\n",
      "â©\n",
      "â€\n",
      "â€“\n",
      "ï¸\n",
      "â€¦\n",
      "â€˜\n",
      "â€”\n",
      "â€¢\n",
      "â€\n",
      "â€œ\n",
      "â€™\n"
     ]
    }
   ],
   "source": [
    "for i in unicodes_to_remove:\n",
    "    print(i.encode('utf-8').decode('unicode-escape'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomodapiArm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
