{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re, nltk\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn, gensim\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.corpora import Dictionary\n",
    "sys.path.append(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/src/')\n",
    "os.chdir(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/data/')\n",
    "from utils import preprocess_for_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romainbourgeois/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/romainbourgeois/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/romainbourgeois/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "data = preprocess_for_bow('data.csv')\n",
    "text_data = data['text']\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "tokenized_data = [[token.strip() for token in tokenizer.tokenize(text)] for text in text_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30191, 53784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tomodapiArm/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([21076,   685,  1682,  4753,  1995]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(X)\n",
    "clusters = km.labels_.tolist()\n",
    "np.unique(np.array(clusters), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)  \n",
    "#pca_result = pca.fit_transform(X.toarray())\n",
    "#print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/umap-learn/\n",
    "umap_model = umap.UMAP(n_neighbors=10, min_dist=0.3)\n",
    "#umap_result = umap_model.fit_transform(X.toarray())\n",
    "\n",
    "# Plot the UMAP visualization\n",
    "#plt.scatter(umap_result[:, 0], umap_result[:, 1])\n",
    "#plt.title(\"UMAP Visualization\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(documents=tokenized_data, prune_at=None)\n",
    "corpus = [dictionary.doc2bow(seq) for seq in tokenized_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.029*\"118\" + 0.027*\"165\" + 0.027*\"5164\" + 0.024*\"283\" + 0.019*\"30\" + 0.016*\"3158\" + 0.014*\"219\" + 0.011*\"498\" + 0.010*\"1651\" + 0.010*\"46\"'),\n",
       " (1,\n",
       "  '0.029*\"69\" + 0.025*\"85\" + 0.015*\"30\" + 0.014*\"28\" + 0.012*\"151\" + 0.007*\"5111\" + 0.007*\"2786\" + 0.007*\"552\" + 0.007*\"11\" + 0.007*\"138\"'),\n",
       " (2,\n",
       "  '0.055*\"167\" + 0.046*\"2465\" + 0.029*\"1456\" + 0.014*\"126\" + 0.014*\"148\" + 0.013*\"248\" + 0.011*\"6138\" + 0.009*\"7554\" + 0.008*\"5410\" + 0.008*\"2161\"'),\n",
       " (3,\n",
       "  '0.015*\"8951\" + 0.015*\"1904\" + 0.014*\"2112\" + 0.012*\"1617\" + 0.011*\"8560\" + 0.011*\"935\" + 0.011*\"8900\" + 0.010*\"3425\" + 0.010*\"5786\" + 0.010*\"12565\"'),\n",
       " (4,\n",
       "  '0.029*\"283\" + 0.019*\"2854\" + 0.014*\"271\" + 0.012*\"6623\" + 0.010*\"20863\" + 0.009*\"14286\" + 0.009*\"118\" + 0.008*\"165\" + 0.008*\"641\" + 0.008*\"935\"'),\n",
       " (5,\n",
       "  '0.025*\"118\" + 0.020*\"6028\" + 0.014*\"151\" + 0.012*\"111\" + 0.012*\"69\" + 0.011*\"609\" + 0.010*\"25\" + 0.010*\"6451\" + 0.009*\"100\" + 0.008*\"935\"'),\n",
       " (6,\n",
       "  '0.019*\"935\" + 0.019*\"118\" + 0.017*\"1059\" + 0.014*\"1735\" + 0.013*\"3257\" + 0.010*\"4728\" + 0.008*\"1358\" + 0.008*\"2603\" + 0.008*\"870\" + 0.006*\"10595\"'),\n",
       " (7,\n",
       "  '0.034*\"5486\" + 0.014*\"30\" + 0.013*\"2956\" + 0.013*\"4178\" + 0.013*\"4482\" + 0.011*\"1789\" + 0.010*\"1711\" + 0.009*\"5909\" + 0.009*\"1750\" + 0.009*\"1778\"'),\n",
       " (8,\n",
       "  '0.013*\"118\" + 0.012*\"1334\" + 0.009*\"30\" + 0.009*\"935\" + 0.008*\"28\" + 0.008*\"441\" + 0.007*\"452\" + 0.007*\"52\" + 0.006*\"89\" + 0.006*\"149\"'),\n",
       " (9,\n",
       "  '0.019*\"806\" + 0.019*\"277\" + 0.012*\"498\" + 0.011*\"283\" + 0.011*\"30\" + 0.009*\"165\" + 0.009*\"46\" + 0.008*\"665\" + 0.008*\"1147\" + 0.008*\"12\"')]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LdaModel # https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "\"\"\"Online Learning for LDA: stochastic optim -> no need to retrain whole corpus when corpus augments -> data hold in memory\n",
    "    'auto': how asymmetric priors learnt -> \n",
    "\"\"\"\n",
    "lda = LdaModel(corpus, num_topics=10,\n",
    "               id2word= dictionary,\n",
    "               distributed=True,\n",
    "               chunksize=2000, #training chunks\n",
    "               decay=0.5, # rate at which previous lambda value is forgotten (0.5,1)\n",
    "               passes=1, #training epochs\n",
    "               update_every=1, #number of documents to be iterated through for each update (during model deployement: set 0 if only need batch training over given corpus)\n",
    "               alpha='symmetric', #document/topic priors - array | symmetric=1/num_topics | 'asymmetric'=(topic_index + sqrt(num_topics)) | 'auto': learns asymmetric from corpus (need distributed set to True) \n",
    "               eta='symmetric', #topic-word  priors - shape (num_topics, num_words) or vector for equal priors accross words\n",
    "                                #asymmetric and auto possible but equal distrib across words\n",
    "               offset=1, #slow down first iter -> math:`\\\\tau_0` from `'Online Learning for LDA'\n",
    "               eval_every=10, #log perplexity -> needed for auto ? \n",
    "               iterations=50, #maximum iter over corpus for inference \n",
    "               gamma_threshold=0.001, #minimum change in the value of the gamma parameters to continue iterating\n",
    "               minimum_probability=0.01, #filter out topic prob lower than that\n",
    "               random_state=None,\n",
    "               ns_conf=None, #optional: for distributed learning\n",
    "               minimum_phi_value=0.01, #lowerbound for topic/word\n",
    "               per_word_topics=False, #if true: also return topic/words distrib when calling .get_document_topics(\n",
    "               callbacks=None,\n",
    "               dtype=np.float32)\n",
    "            \n",
    "topic_info = lda.print_topics(num_topics=10, num_words=10)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "need to call the index of corpus dictionary to retrieve the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.29467753),\n",
       " (1, 0.6550206),\n",
       " (2, 0.0062861973),\n",
       " (3, 0.006286224),\n",
       " (4, 0.006286416),\n",
       " (5, 0.0062913466),\n",
       " (6, 0.0062875925),\n",
       " (7, 0.0062872106),\n",
       " (8, 0.006290098),\n",
       " (9, 0.0062868167)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus[0], minimum_probability=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lda multicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"tweet\" + 0.017*\"show\" + 0.012*\"want\" + 0.010*\"add\" + 0.010*\"try\" + 0.010*\"birdwatch\" + 0.009*\"context\" + 0.009*\"hit\" + 0.009*\"mislead\" + 0.009*\"contribute\"'),\n",
       " (1,\n",
       "  '0.009*\"people\" + 0.006*\"covid\" + 0.005*\"say\" + 0.005*\"coronavirus\" + 0.004*\"president\" + 0.004*\"show\" + 0.004*\"make\" + 0.004*\"vaccine\" + 0.004*\"use\" + 0.003*\"find\"'),\n",
       " (2,\n",
       "  '0.010*\"covid\" + 0.009*\"show\" + 0.006*\"video\" + 0.005*\"trump\" + 0.005*\"vaccine\" + 0.005*\"president\" + 0.005*\"people\" + 0.005*\"death\" + 0.004*\"win\" + 0.004*\"get\"'),\n",
       " (3,\n",
       "  '0.011*\"say\" + 0.009*\"trump\" + 0.006*\"covid\" + 0.005*\"people\" + 0.005*\"take\" + 0.004*\"state\" + 0.004*\"make\" + 0.004*\"show\" + 0.004*\"claim\" + 0.003*\"video\"'),\n",
       " (4,\n",
       "  '0.010*\"covid\" + 0.008*\"vaccine\" + 0.008*\"know\" + 0.008*\"trump\" + 0.007*\"say\" + 0.006*\"people\" + 0.006*\"president\" + 0.006*\"get\" + 0.004*\"government\" + 0.004*\"take\"'),\n",
       " (5,\n",
       "  '0.012*\"tweet\" + 0.008*\"covid\" + 0.008*\"trump\" + 0.008*\"get\" + 0.006*\"want\" + 0.006*\"try\" + 0.006*\"people\" + 0.006*\"birdwatch\" + 0.005*\"add\" + 0.005*\"context\"'),\n",
       " (6,\n",
       "  '0.008*\"say\" + 0.008*\"show\" + 0.007*\"covid\" + 0.006*\"year\" + 0.006*\"trump\" + 0.006*\"vaccine\" + 0.005*\"claim\" + 0.004*\"state\" + 0.004*\"die\" + 0.004*\"coronavirus\"'),\n",
       " (7,\n",
       "  '0.011*\"trump\" + 0.008*\"show\" + 0.007*\"president\" + 0.006*\"china\" + 0.005*\"coronavirus\" + 0.005*\"covid\" + 0.005*\"vote\" + 0.004*\"people\" + 0.004*\"video\" + 0.004*\"biden\"'),\n",
       " (8,\n",
       "  '0.010*\"covid\" + 0.007*\"state\" + 0.006*\"show\" + 0.005*\"election\" + 0.005*\"make\" + 0.005*\"president\" + 0.004*\"trump\" + 0.004*\"people\" + 0.004*\"woman\" + 0.004*\"say\"'),\n",
       " (9,\n",
       "  '0.012*\"people\" + 0.007*\"say\" + 0.005*\"show\" + 0.005*\"twitter\" + 0.004*\"covid\" + 0.004*\"use\" + 0.004*\"trump\" + 0.004*\"com\" + 0.003*\"come\" + 0.003*\"make\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "lda = LdaMulticore(corpus=corpus, num_topics=10, \n",
    "                 id2word=dictionary, workers=None,\n",
    "                 chunksize=2000, \n",
    "                 passes=1, \n",
    "                 batch=False, \n",
    "                 alpha='symmetric',\n",
    "                 eta=None, \n",
    "                 decay=0.5, \n",
    "                 offset=1.0, \n",
    "                 eval_every=10, \n",
    "                 iterations=50,\n",
    "                 gamma_threshold=0.001, \n",
    "                 random_state=None, \n",
    "                 minimum_probability=0.01,\n",
    "                 minimum_phi_value=0.01, \n",
    "                 per_word_topics=False, \n",
    "                 dtype=np.float32)\n",
    "topic_info = lda.print_topics(num_topics=10, num_words=10)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.0047817216),\n",
       " (1, 0.0047822436),\n",
       " (2, 0.0047825268),\n",
       " (3, 0.0047821915),\n",
       " (4, 0.004782601),\n",
       " (5, 0.0047822236),\n",
       " (6, 0.0047820755),\n",
       " (7, 0.9569583),\n",
       " (8, 0.0047830148),\n",
       " (9, 0.0047830935)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus[0], minimum_probability=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.022*tweet + 0.012*try + 0.011*add + 0.011*want + 0.011*context + 0.010*mislead + 0.009*hit + 0.009*contribute + 0.008*menu + 0.007*covid'),\n",
       " (1,\n",
       "  '0.009*show + 0.007*trump + 0.006*covid + 0.006*people + 0.006*president + 0.005*say + 0.005*video + 0.005*vaccine + 0.004*election + 0.003*get'),\n",
       " (2,\n",
       "  '0.007*show + 0.005*covid + 0.005*trump + 0.005*people + 0.004*say + 0.003*president + 0.003*video + 0.003*vaccine + 0.002*get + 0.002*state'),\n",
       " (3,\n",
       "  '0.005*show + 0.004*trump + 0.004*covid + 0.003*people + 0.003*president + 0.003*say + 0.003*earthquake + 0.002*get + 0.002*video + 0.002*vaccine'),\n",
       " (4,\n",
       "  '0.004*show + 0.004*covid + 0.003*trump + 0.003*president + 0.003*people + 0.002*say + 0.002*video + 0.002*coronavirus + 0.002*state + 0.002*vaccine'),\n",
       " (5,\n",
       "  '0.004*covid + 0.003*trump + 0.003*show + 0.003*people + 0.003*say + 0.002*president + 0.002*get + 0.002*video + 0.002*vaccine + 0.001*coronavirus'),\n",
       " (6,\n",
       "  '0.004*tweet + 0.003*show + 0.003*covid + 0.003*trump + 0.003*birdwatch + 0.003*people + 0.003*get + 0.002*president + 0.002*try + 0.002*say'),\n",
       " (7,\n",
       "  '0.004*show + 0.004*trump + 0.004*covid + 0.003*people + 0.003*president + 0.002*say + 0.002*get + 0.002*state + 0.002*tweet + 0.002*vaccine'),\n",
       " (8,\n",
       "  '0.004*covid + 0.003*show + 0.003*people + 0.002*vaccine + 0.002*get + 0.002*say + 0.002*trump + 0.002*president + 0.002*video + 0.002*state'),\n",
       " (9,\n",
       "  '0.003*covid + 0.003*show + 0.003*trump + 0.002*people + 0.002*say + 0.002*president + 0.002*vaccine + 0.002*video + 0.002*get + 0.001*state')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import HdpModel # https://radimrehurek.com/gensim/models/hdpmodel.html\n",
    "hdp = HdpModel(corpus, dictionary)\n",
    "topic_info = hdp.print_topics(num_topics=10, num_words=10)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomodapiArm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
