{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import re, nltk\n",
    "from nltk import pos_tag\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import umap\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn, gensim\n",
    "import Pyro4\n",
    "from sklearn.decomposition import PCA\n",
    "from gensim.corpora import Dictionary\n",
    "sys.path.append(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/src/')\n",
    "os.chdir(os.path.expanduser(\"~\")+'/Desktop/topic_modeling/fine_grained_topic_modeling_for_misinformation/data/')\n",
    "from utils import preprocess_for_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocess_for_bow('data.csv')\n",
    "text_data = data['text']\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "tokenized_data = [[token.strip() for token in tokenizer.tokenize(text)] for text in text_data]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf and document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30191, 53784)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(text_data)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "dist = 1 - cosine_similarity(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/tomodapiArm/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4]), array([21076,   685,  1682,  4753,  1995]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 5\n",
    "km = KMeans(n_clusters=num_clusters)\n",
    "km.fit(X)\n",
    "clusters = km.labels_.tolist()\n",
    "np.unique(np.array(clusters), return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10)  \n",
    "#pca_result = pca.fit_transform(X.toarray())\n",
    "#print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pypi.org/project/umap-learn/\n",
    "umap_model = umap.UMAP(n_neighbors=10, min_dist=0.3)\n",
    "#umap_result = umap_model.fit_transform(X.toarray())\n",
    "\n",
    "# Plot the UMAP visualization\n",
    "#plt.scatter(umap_result[:, 0], umap_result[:, 1])\n",
    "#plt.title(\"UMAP Visualization\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENSIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = Dictionary(documents=tokenized_data, prune_at=None)\n",
    "corpus = [dictionary.doc2bow(seq) for seq in tokenized_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"muslim\" + 0.017*\"offer\" + 0.012*\"migrant\" + 0.010*\"sister\" + 0.010*\"accuse\" + 0.009*\"com\" + 0.009*\"government\" + 0.008*\"endorse\" + 0.008*\"establishment\" + 0.008*\"error\"'),\n",
       " (1,\n",
       "  '0.027*\"tweet\" + 0.021*\"add\" + 0.016*\"whitehouse\" + 0.012*\"area\" + 0.011*\"google\" + 0.010*\"hit\" + 0.009*\"want\" + 0.009*\"resign\" + 0.009*\"try\" + 0.008*\"mission\"'),\n",
       " (2,\n",
       "  '0.013*\"faith\" + 0.011*\"capitol\" + 0.010*\"god\" + 0.009*\"employee\" + 0.009*\"charge\" + 0.009*\"novelcoronavirus\" + 0.009*\"christ\" + 0.009*\"hindu\" + 0.008*\"lay\" + 0.008*\"journalist\"'),\n",
       " (3,\n",
       "  '0.022*\"covid\" + 0.022*\"show\" + 0.015*\"video\" + 0.014*\"case\" + 0.013*\"coronavirus\" + 0.012*\"death\" + 0.011*\"people\" + 0.010*\"woman\" + 0.010*\"year\" + 0.010*\"report\"'),\n",
       " (4,\n",
       "  '0.050*\"show\" + 0.029*\"photo\" + 0.029*\"video\" + 0.014*\"protest\" + 0.011*\"india\" + 0.010*\"farmer\" + 0.010*\"world\" + 0.008*\"party\" + 0.006*\"modi\" + 0.006*\"secretary\"'),\n",
       " (5,\n",
       "  '0.019*\"people\" + 0.014*\"covid\" + 0.012*\"document\" + 0.010*\"say\" + 0.010*\"mask\" + 0.010*\"time\" + 0.010*\"face\" + 0.009*\"county\" + 0.008*\"student\" + 0.008*\"life\"'),\n",
       " (6,\n",
       "  '0.021*\"vaccine\" + 0.019*\"coronavirus\" + 0.011*\"bill\" + 0.011*\"assange\" + 0.009*\"gate\" + 0.008*\"george\" + 0.008*\"covid\" + 0.008*\"announce\" + 0.008*\"administration\" + 0.007*\"china\"'),\n",
       " (7,\n",
       "  '0.042*\"image\" + 0.024*\"write\" + 0.018*\"post\" + 0.014*\"shoot\" + 0.010*\"medium\" + 0.009*\"twitter\" + 0.009*\"news\" + 0.008*\"article\" + 0.008*\"account\" + 0.008*\"lord\"'),\n",
       " (8,\n",
       "  '0.031*\"pope\" + 0.016*\"francis\" + 0.013*\"minister\" + 0.013*\"ford\" + 0.013*\"court\" + 0.011*\"say\" + 0.008*\"statement\" + 0.008*\"justice\" + 0.008*\"supremecourt\" + 0.008*\"father\"'),\n",
       " (9,\n",
       "  '0.035*\"president\" + 0.030*\"trump\" + 0.021*\"say\" + 0.015*\"us\" + 0.014*\"biden\" + 0.013*\"donald\" + 0.013*\"election\" + 0.012*\"joe\" + 0.010*\"show\" + 0.009*\"state\"')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LdaModel # https://radimrehurek.com/gensim/models/ldamodel.html\n",
    "\"\"\"Online Learning for LDA: stochastic optim -> no need to retrain whole corpus when corpus augments -> data hold in memory\n",
    "    'auto': how asymmetric priors learnt -> \n",
    "\"\"\"\n",
    "lda = LdaModel(corpus, num_topics=10,\n",
    "               id2word= dictionary,\n",
    "               distributed=False,\n",
    "               chunksize=2000, #training chunks\n",
    "               decay=0.5, # rate at which previous lambda value is forgotten (0.5,1)\n",
    "               passes=1, #training epochs\n",
    "               update_every=1, #number of documents to be iterated through for each update (during model deployement: set 0 if only need batch training over given corpus)\n",
    "               alpha='symmetric', #document/topic priors - array | symmetric=1/num_topics | 'asymmetric'=(topic_index + sqrt(num_topics)) | 'auto': learns asymmetric from corpus (need distributed set to True) \n",
    "               eta='symmetric', #topic-word  priors - shape (num_topics, num_words) or vector for equal priors accross words\n",
    "                                #asymmetric and auto possible but equal distrib across words\n",
    "               offset=1, #slow down first iter -> math:`\\\\tau_0` from `'Online Learning for LDA'\n",
    "               eval_every=10, #log perplexity -> needed for auto ? \n",
    "               iterations=50, #maximum iter over corpus for inference \n",
    "               gamma_threshold=0.001, #minimum change in the value of the gamma parameters to continue iterating\n",
    "               minimum_probability=0.01, #filter out topic prob lower than that\n",
    "               random_state=None,\n",
    "               ns_conf=None, #optional: for distributed learning\n",
    "               minimum_phi_value=0.01, #lowerbound for topic/word\n",
    "               per_word_topics=False, #if true: also return topic/words distrib when calling .get_document_topics(\n",
    "               callbacks=None,\n",
    "               dtype=np.float32)\n",
    "            \n",
    "topic_info = lda.print_topics(num_topics=10, num_words=10)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.026*\"muslim\" + 0.017*\"offer\" + 0.012*\"migrant\" + 0.010*\"sister\" + 0.010*\"accuse\" + 0.009*\"com\" + 0.009*\"government\" + 0.008*\"endorse\" + 0.008*\"establishment\" + 0.008*\"error\"'),\n",
       " (1,\n",
       "  '0.027*\"tweet\" + 0.021*\"add\" + 0.016*\"whitehouse\" + 0.012*\"area\" + 0.011*\"google\" + 0.010*\"hit\" + 0.009*\"want\" + 0.009*\"resign\" + 0.009*\"try\" + 0.008*\"mission\"'),\n",
       " (2,\n",
       "  '0.013*\"faith\" + 0.011*\"capitol\" + 0.010*\"god\" + 0.009*\"employee\" + 0.009*\"charge\" + 0.009*\"novelcoronavirus\" + 0.009*\"christ\" + 0.009*\"hindu\" + 0.008*\"lay\" + 0.008*\"journalist\"'),\n",
       " (3,\n",
       "  '0.022*\"covid\" + 0.022*\"show\" + 0.015*\"video\" + 0.014*\"case\" + 0.013*\"coronavirus\" + 0.012*\"death\" + 0.011*\"people\" + 0.010*\"woman\" + 0.010*\"year\" + 0.010*\"report\"'),\n",
       " (4,\n",
       "  '0.050*\"show\" + 0.029*\"photo\" + 0.029*\"video\" + 0.014*\"protest\" + 0.011*\"india\" + 0.010*\"farmer\" + 0.010*\"world\" + 0.008*\"party\" + 0.006*\"modi\" + 0.006*\"secretary\"'),\n",
       " (5,\n",
       "  '0.019*\"people\" + 0.014*\"covid\" + 0.012*\"document\" + 0.010*\"say\" + 0.010*\"mask\" + 0.010*\"time\" + 0.010*\"face\" + 0.009*\"county\" + 0.008*\"student\" + 0.008*\"life\"'),\n",
       " (6,\n",
       "  '0.021*\"vaccine\" + 0.019*\"coronavirus\" + 0.011*\"bill\" + 0.011*\"assange\" + 0.009*\"gate\" + 0.008*\"george\" + 0.008*\"covid\" + 0.008*\"announce\" + 0.008*\"administration\" + 0.007*\"china\"'),\n",
       " (7,\n",
       "  '0.042*\"image\" + 0.024*\"write\" + 0.018*\"post\" + 0.014*\"shoot\" + 0.010*\"medium\" + 0.009*\"twitter\" + 0.009*\"news\" + 0.008*\"article\" + 0.008*\"account\" + 0.008*\"lord\"'),\n",
       " (8,\n",
       "  '0.031*\"pope\" + 0.016*\"francis\" + 0.013*\"minister\" + 0.013*\"ford\" + 0.013*\"court\" + 0.011*\"say\" + 0.008*\"statement\" + 0.008*\"justice\" + 0.008*\"supremecourt\" + 0.008*\"father\"'),\n",
       " (9,\n",
       "  '0.035*\"president\" + 0.030*\"trump\" + 0.021*\"say\" + 0.015*\"us\" + 0.014*\"biden\" + 0.013*\"donald\" + 0.013*\"election\" + 0.012*\"joe\" + 0.010*\"show\" + 0.009*\"state\"')]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'biologicalweapons'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### lda multicore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.019*\"tweet\" + 0.017*\"show\" + 0.012*\"want\" + 0.010*\"add\" + 0.010*\"try\" + 0.010*\"birdwatch\" + 0.009*\"context\" + 0.009*\"hit\" + 0.009*\"mislead\" + 0.009*\"contribute\"'),\n",
       " (1,\n",
       "  '0.009*\"people\" + 0.006*\"covid\" + 0.005*\"say\" + 0.005*\"coronavirus\" + 0.004*\"president\" + 0.004*\"show\" + 0.004*\"make\" + 0.004*\"vaccine\" + 0.004*\"use\" + 0.003*\"find\"'),\n",
       " (2,\n",
       "  '0.010*\"covid\" + 0.009*\"show\" + 0.006*\"video\" + 0.005*\"trump\" + 0.005*\"vaccine\" + 0.005*\"president\" + 0.005*\"people\" + 0.005*\"death\" + 0.004*\"win\" + 0.004*\"get\"'),\n",
       " (3,\n",
       "  '0.011*\"say\" + 0.009*\"trump\" + 0.006*\"covid\" + 0.005*\"people\" + 0.005*\"take\" + 0.004*\"state\" + 0.004*\"make\" + 0.004*\"show\" + 0.004*\"claim\" + 0.003*\"video\"'),\n",
       " (4,\n",
       "  '0.010*\"covid\" + 0.008*\"vaccine\" + 0.008*\"know\" + 0.008*\"trump\" + 0.007*\"say\" + 0.006*\"people\" + 0.006*\"president\" + 0.006*\"get\" + 0.004*\"government\" + 0.004*\"take\"'),\n",
       " (5,\n",
       "  '0.012*\"tweet\" + 0.008*\"covid\" + 0.008*\"trump\" + 0.008*\"get\" + 0.006*\"want\" + 0.006*\"try\" + 0.006*\"people\" + 0.006*\"birdwatch\" + 0.005*\"add\" + 0.005*\"context\"'),\n",
       " (6,\n",
       "  '0.008*\"say\" + 0.008*\"show\" + 0.007*\"covid\" + 0.006*\"year\" + 0.006*\"trump\" + 0.006*\"vaccine\" + 0.005*\"claim\" + 0.004*\"state\" + 0.004*\"die\" + 0.004*\"coronavirus\"'),\n",
       " (7,\n",
       "  '0.011*\"trump\" + 0.008*\"show\" + 0.007*\"president\" + 0.006*\"china\" + 0.005*\"coronavirus\" + 0.005*\"covid\" + 0.005*\"vote\" + 0.004*\"people\" + 0.004*\"video\" + 0.004*\"biden\"'),\n",
       " (8,\n",
       "  '0.010*\"covid\" + 0.007*\"state\" + 0.006*\"show\" + 0.005*\"election\" + 0.005*\"make\" + 0.005*\"president\" + 0.004*\"trump\" + 0.004*\"people\" + 0.004*\"woman\" + 0.004*\"say\"'),\n",
       " (9,\n",
       "  '0.012*\"people\" + 0.007*\"say\" + 0.005*\"show\" + 0.005*\"twitter\" + 0.004*\"covid\" + 0.004*\"use\" + 0.004*\"trump\" + 0.004*\"com\" + 0.003*\"come\" + 0.003*\"make\"')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import LdaMulticore\n",
    "lda = LdaMulticore(corpus=corpus, num_topics=10, \n",
    "                 id2word=dictionary, workers=None,\n",
    "                 chunksize=2000, \n",
    "                 passes=1, \n",
    "                 batch=False, \n",
    "                 alpha='symmetric',\n",
    "                 eta=None, \n",
    "                 decay=0.5, \n",
    "                 offset=1.0, \n",
    "                 eval_every=10, \n",
    "                 iterations=50,\n",
    "                 gamma_threshold=0.001, \n",
    "                 random_state=None, \n",
    "                 minimum_probability=0.01,\n",
    "                 minimum_phi_value=0.01, \n",
    "                 per_word_topics=False, \n",
    "                 dtype=np.float32)\n",
    "topic_info = lda.print_topics(num_topics=10, num_words=10)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.09766076),\n",
       " (3, 0.09164561),\n",
       " (5, 0.25104368),\n",
       " (7, 0.44094688),\n",
       " (9, 0.09481776)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.get_document_topics(corpus)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30191"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.022*tweet + 0.012*try + 0.011*add + 0.011*want + 0.011*context + 0.010*mislead + 0.009*hit + 0.009*contribute + 0.008*menu + 0.007*covid'),\n",
       " (1,\n",
       "  '0.009*show + 0.007*trump + 0.006*covid + 0.006*people + 0.006*president + 0.005*say + 0.005*video + 0.005*vaccine + 0.004*election + 0.003*get'),\n",
       " (2,\n",
       "  '0.007*show + 0.005*covid + 0.005*trump + 0.005*people + 0.004*say + 0.003*president + 0.003*video + 0.003*vaccine + 0.002*get + 0.002*state'),\n",
       " (3,\n",
       "  '0.005*show + 0.004*trump + 0.004*covid + 0.003*people + 0.003*president + 0.003*say + 0.003*earthquake + 0.002*get + 0.002*video + 0.002*vaccine'),\n",
       " (4,\n",
       "  '0.004*show + 0.004*covid + 0.003*trump + 0.003*president + 0.003*people + 0.002*say + 0.002*video + 0.002*coronavirus + 0.002*state + 0.002*vaccine'),\n",
       " (5,\n",
       "  '0.004*covid + 0.003*trump + 0.003*show + 0.003*people + 0.003*say + 0.002*president + 0.002*get + 0.002*video + 0.002*vaccine + 0.001*coronavirus'),\n",
       " (6,\n",
       "  '0.004*tweet + 0.003*show + 0.003*covid + 0.003*trump + 0.003*birdwatch + 0.003*people + 0.003*get + 0.002*president + 0.002*try + 0.002*say'),\n",
       " (7,\n",
       "  '0.004*show + 0.004*trump + 0.004*covid + 0.003*people + 0.003*president + 0.002*say + 0.002*get + 0.002*state + 0.002*tweet + 0.002*vaccine'),\n",
       " (8,\n",
       "  '0.004*covid + 0.003*show + 0.003*people + 0.002*vaccine + 0.002*get + 0.002*say + 0.002*trump + 0.002*president + 0.002*video + 0.002*state'),\n",
       " (9,\n",
       "  '0.003*covid + 0.003*show + 0.003*trump + 0.002*people + 0.002*say + 0.002*president + 0.002*vaccine + 0.002*video + 0.002*get + 0.001*state')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import HdpModel # https://radimrehurek.com/gensim/models/hdpmodel.html\n",
    "hdp = HdpModel(corpus, dictionary)\n",
    "topic_info = hdp.print_topics(num_topics=10, num_words=10)\n",
    "topic_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomodapiArm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
